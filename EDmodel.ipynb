{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alleyibrahim/modus/blob/main/EDmodel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMp24Aklj65g"
      },
      "source": [
        "# Convert audio to midi files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N270edeX4fDJ",
        "outputId": "353d028a-8307-4966-f7bd-fd284322f466"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GHnrszJEsoqM"
      },
      "outputs": [],
      "source": [
        "# Define the path to the zip file and the extraction directory\n",
        "zip_path = '/content/drive/MyDrive/DEAMds/archive.zip'\n",
        "extract_dir = '/content/drive/MyDrive/DEAMds'\n",
        "\n",
        "# Extract the zip file\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)\n",
        "\n",
        "# Verify the extraction\n",
        "os.listdir(extract_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "37U31bPA5PXf"
      },
      "outputs": [],
      "source": [
        "pip install basic-pitch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "GBBcKp586leI"
      },
      "outputs": [],
      "source": [
        "pip install pydub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "nwTpv00YA1zd"
      },
      "outputs": [],
      "source": [
        "pip install librosa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "v9oY9kqThyiG"
      },
      "outputs": [],
      "source": [
        "pip install pretty_midi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "C1FPUgKj4kvm"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from basic_pitch.inference import predict_and_save\n",
        "\n",
        "# Define directories\n",
        "input_audio_dir = '/content/drive/MyDrive/DEAMds/DEAM_audio/MEMD_audio'\n",
        "output_midi_dir = '/content/drive/MyDrive/DEAMds/ProcessedFiles/midi_files'\n",
        "model_path = '/content/drive/MyDrive/DEAMds/ProcessedFiles/basic_pitch/nmp.tflite'\n",
        "\n",
        "# Convert MP3 to MIDI using Basic Pitch\n",
        "audio_files = [f for f in os.listdir(input_audio_dir) if f.endswith('.mp3')]\n",
        "\n",
        "print(f\"Found {len(audio_files)} MP3 files in {input_audio_dir}\")\n",
        "\n",
        "for audio_file in audio_files:\n",
        "    input_audio_path = os.path.join(input_audio_dir, audio_file)\n",
        "    output_directory = output_midi_dir  # Output directory for all files\n",
        "\n",
        "    try:\n",
        "        print(f\"Predicting MIDI for {input_audio_path}\")\n",
        "\n",
        "        # Perform the conversion\n",
        "        predict_and_save(\n",
        "\n",
        "            [input_audio_path],  # List of input audio paths\n",
        "            output_directory,    # Output directory for saving\n",
        "            save_midi=True,\n",
        "            sonify_midi=False,\n",
        "            save_model_outputs=False,\n",
        "            save_notes=False,\n",
        "            model_or_model_path=model_path\n",
        "        )\n",
        "        print(f\"Converted {input_audio_path} to MIDI in {output_directory}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {input_audio_path}: {e}\")\n",
        "\n",
        "print(\"Conversion process completed.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTSSZtruLS22"
      },
      "source": [
        "# Combine features and annotations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sa8PDQblheW1",
        "outputId": "a0372ee0-e544-42de-df16-328d371d6e57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Combined features and annotations for the first 500 files saved to /content/drive/MyDrive/DEAMds/ProcessedFiles/combined_features_annotations.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "def process_and_merge_batch(batch_files, features_dir, static_annotations_df, dynamic_valence_df, dynamic_arousal_df):\n",
        "    batch_list = []\n",
        "\n",
        "    for feature_file in batch_files:\n",
        "        song_id = os.path.splitext(feature_file)[0]\n",
        "        df = pd.read_csv(os.path.join(features_dir, feature_file))\n",
        "        df['song_id'] = song_id\n",
        "        batch_list.append(df)\n",
        "\n",
        "    batch_df = pd.concat(batch_list, ignore_index=True)\n",
        "\n",
        "    # Ensure song_id is of type string\n",
        "    batch_df['song_id'] = batch_df['song_id'].astype(str)\n",
        "\n",
        "    # Merge with static annotations\n",
        "    merged_batch_df = batch_df.merge(static_annotations_df, on='song_id', how='inner')\n",
        "\n",
        "    # Merge with dynamic annotations\n",
        "    merged_batch_df = merged_batch_df.merge(dynamic_valence_df, on='song_id', how='inner')\n",
        "    merged_batch_df = merged_batch_df.merge(dynamic_arousal_df, on='song_id', how='inner')\n",
        "\n",
        "    return merged_batch_df\n",
        "\n",
        "def load_and_merge_features_in_batches(features_dir, static_annotations_df, dynamic_valence_df, dynamic_arousal_df, max_files=500, batch_size=100):\n",
        "    feature_files = [f for f in os.listdir(features_dir) if f.endswith('.csv')][:max_files]  # Limit to first 500 files\n",
        "    output_file = '/content/drive/MyDrive/DEAMds/ProcessedFiles/combined_features_annotations.csv'\n",
        "\n",
        "    first_batch = True\n",
        "    for i in range(0, len(feature_files), batch_size):\n",
        "        batch_files = feature_files[i:i + batch_size]\n",
        "        merged_batch_df = process_and_merge_batch(batch_files, features_dir, static_annotations_df, dynamic_valence_df, dynamic_arousal_df)\n",
        "\n",
        "        # Append to the final output file\n",
        "        if first_batch:\n",
        "            merged_batch_df.to_csv(output_file, index=False, mode='w')\n",
        "            first_batch = False\n",
        "        else:\n",
        "            merged_batch_df.to_csv(output_file, index=False, mode='a', header=False)\n",
        "\n",
        "        del merged_batch_df  # Free up memory\n",
        "\n",
        "    return output_file\n",
        "\n",
        "# Paths to features and annotations\n",
        "features_dir = '/content/drive/MyDrive/DEAMds/features/features'\n",
        "static_annotations_1_path = '/content/drive/MyDrive/DEAMds/DEAM_Annotations/annotations/annotations_averaged_per_song/song_level/static_annotations_averaged_songs_1_2000.csv'\n",
        "static_annotations_2_path = '/content/drive/MyDrive/DEAMds/DEAM_Annotations/annotations/annotations_averaged_per_song/song_level/static_annotations_averaged_songs_2000_2058.csv'\n",
        "dynamic_valence_path = '/content/drive/MyDrive/DEAMds/DEAM_Annotations/annotations/annotations_averaged_per_song/dynamic/valence.csv'\n",
        "dynamic_arousal_path = '/content/drive/MyDrive/DEAMds/DEAM_Annotations/annotations/annotations_averaged_per_song/dynamic/arousal.csv'\n",
        "\n",
        "# Load Static Annotations (Averaged per Song)\n",
        "static_annotations_1 = pd.read_csv(static_annotations_1_path)\n",
        "static_annotations_2 = pd.read_csv(static_annotations_2_path)\n",
        "static_annotations_df = pd.concat([static_annotations_1, static_annotations_2], ignore_index=True)\n",
        "\n",
        "# Ensure song_id is of type string\n",
        "static_annotations_df['song_id'] = static_annotations_df['song_id'].astype(str)\n",
        "\n",
        "# Load Dynamic Annotations (Averaged per Song)\n",
        "dynamic_valence_df = pd.read_csv(dynamic_valence_path)\n",
        "dynamic_arousal_df = pd.read_csv(dynamic_arousal_path)\n",
        "\n",
        "# Ensure song_id is of type string\n",
        "dynamic_valence_df['song_id'] = dynamic_valence_df['song_id'].astype(str)\n",
        "dynamic_arousal_df['song_id'] = dynamic_arousal_df['song_id'].astype(str)\n",
        "\n",
        "# Process and merge features in batches, limiting to the first 500 files\n",
        "output_file = load_and_merge_features_in_batches(features_dir, static_annotations_df, dynamic_valence_df, dynamic_arousal_df, max_files=500)\n",
        "\n",
        "print(f\"Combined features and annotations for the first 500 files saved to {output_file}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQcitiw3ojHZ"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKq4LEVAeMSO",
        "outputId": "fa71fee1-d37e-4826-ece7-298f23858089"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-7-0909ce4f68a7>:20: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  combined_df[time_series_cols] = combined_df[time_series_cols].fillna(method='ffill').fillna(method='bfill')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Remaining null values:\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the combined dataframe\n",
        "combined_csv_path = '/content/drive/MyDrive/DEAMds/ProcessedFiles/combined_features_annotations.csv'\n",
        "combined_df = pd.read_csv(combined_csv_path)\n",
        "\n",
        "# Drop columns with all null values\n",
        "combined_df.dropna(axis=1, how='all', inplace=True)\n",
        "\n",
        "# Drop rows where all values are null\n",
        "combined_df.dropna(axis=0, how='all', inplace=True)\n",
        "\n",
        "# Identify time-series columns based on the naming pattern \"sample_\"\n",
        "time_series_cols = [col for col in combined_df.columns if col.startswith('sample_')]\n",
        "\n",
        "# Identify non-time-series columns\n",
        "non_time_series_cols = [col for col in combined_df.columns if col not in time_series_cols]\n",
        "\n",
        "# Handle missing values in time-series data using forward fill, then backward fill\n",
        "combined_df[time_series_cols] = combined_df[time_series_cols].fillna(method='ffill').fillna(method='bfill')\n",
        "\n",
        "# Handle missing values in other data by replacing with 0\n",
        "combined_df[non_time_series_cols] = combined_df[non_time_series_cols].fillna(0)\n",
        "\n",
        "# Verify if all null values are handled\n",
        "print(f\"Remaining null values:\\n{combined_df.isnull().sum().sum()}\")\n",
        "\n",
        "# Save cleaned DataFrame to a new CSV file\n",
        "# save_path_cleaned = '/content/drive/MyDrive/DEAMds/ProcessedFiles/combined_annotations_and_features_cleaned.csv'\n",
        "# combined_df.to_csv(save_path_cleaned, index=False)\n",
        "\n",
        "# print(f\"Cleaned and combined DataFrame saved to {save_path_cleaned}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ld_5BSjbJckr",
        "outputId": "51d1a9ce-a2bc-42d9-d377-1aa2fbea1b46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting miditoolkit\n",
            "  Downloading miditoolkit-1.0.1-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from miditoolkit) (3.7.1)\n",
            "Requirement already satisfied: mido>=1.1.16 in /usr/local/lib/python3.10/dist-packages (from miditoolkit) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.7.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.7.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->miditoolkit) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->miditoolkit) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->miditoolkit) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->miditoolkit) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->miditoolkit) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->miditoolkit) (3.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n",
            "Downloading miditoolkit-1.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: miditoolkit\n",
            "Successfully installed miditoolkit-1.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install miditoolkit numpy pandas scikit-learn tensorflow\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhzlazqE0YFA"
      },
      "source": [
        "# Extract midi features and merge with training data features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4xt3_xyBsvnm"
      },
      "outputs": [],
      "source": [
        "import miditoolkit\n",
        "import numpy as np\n",
        "\n",
        "def extract_midi_features(midi_file):\n",
        "    # Load MIDI file\n",
        "    midi_obj = miditoolkit.MidiFile(midi_file)\n",
        "    notes = midi_obj.instruments[0].notes\n",
        "\n",
        "    # Calculate total duration of the MIDI file\n",
        "    total_duration = max(note.end for note in notes) if notes else 0\n",
        "\n",
        "    # Original Features\n",
        "    pitches = [note.pitch for note in notes]\n",
        "    durations = [note.end - note.start for note in notes]\n",
        "    velocities = [note.velocity for note in notes]\n",
        "    tempo = midi_obj.tempo_changes[0].tempo if midi_obj.tempo_changes else 120  # Default tempo\n",
        "    pitch_classes = [pitch % 12 for pitch in pitches]\n",
        "\n",
        "    # *** New Features ***\n",
        "    pitch_class_histogram = np.histogram(pitch_classes, bins=np.arange(13))[0]\n",
        "    note_density = len(notes) / total_duration if total_duration > 0 else 0\n",
        "    melodic_intervals = np.diff(pitches) if len(pitches) > 1 else []\n",
        "\n",
        "    features = {\n",
        "        'mean_pitch': np.mean(pitches) if pitches else 0,\n",
        "        'std_pitch': np.std(pitches) if pitches else 0,\n",
        "        'mean_duration': np.mean(durations) if durations else 0,\n",
        "        'std_duration': np.std(durations) if durations else 0,\n",
        "        'mean_velocity': np.mean(velocities) if velocities else 0,\n",
        "        'std_velocity': np.std(velocities) if velocities else 0,\n",
        "        'tempo': tempo,\n",
        "        'note_density': note_density,\n",
        "        'mean_melodic_interval': np.mean(melodic_intervals) if len(melodic_intervals) > 0 else 0,\n",
        "        'std_melodic_interval': np.std(melodic_intervals) if len(melodic_intervals) > 0 else 0,\n",
        "    }\n",
        "\n",
        "    # *** Add pitch class histogram ***\n",
        "    for i in range(12):\n",
        "        features[f'pitch_class_{i}'] = pitch_class_histogram[i]\n",
        "\n",
        "    return features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2QB2m5XaOUy6"
      },
      "outputs": [],
      "source": [
        "midi_dir = '/content/drive/MyDrive/DEAMds/ProcessedFiles/midi_files'\n",
        "combined_csv_path = '/content/drive/MyDrive/DEAMds/ProcessedFiles/combined_features_annotations.csv'\n",
        "combined_df = pd.read_csv(combined_csv_path)\n",
        "\n",
        "# Extract features for each MIDI file\n",
        "midi_features_list = []\n",
        "for song_id in combined_df['song_id'].unique():\n",
        "    midi_file_path = os.path.join(midi_dir, f\"{song_id}_basic_pitch.mid\")\n",
        "    if os.path.exists(midi_file_path):\n",
        "        features = extract_midi_features(midi_file_path)\n",
        "        features['song_id'] = song_id\n",
        "        midi_features_list.append(features)\n",
        "\n",
        "midi_features_df = pd.DataFrame(midi_features_list)\n",
        "midi_features_df.to_csv('/content/drive/MyDrive/DEAMds/ProcessedFiles/midi_features_new.csv', index=False)\n",
        "\n",
        "# Merge with existing combined_df based on song_id\n",
        "combined_df = pd.merge(combined_df, midi_features_df, on='song_id', how='inner')\n",
        "combined_df.to_csv('/content/drive/MyDrive/DEAMds/ProcessedFiles/midi_f_a_f_new.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZVDVXAn_hCR"
      },
      "source": [
        "# Clean And Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6QCjmxdS_k-M"
      },
      "outputs": [],
      "source": [
        "# Step 5: Clean and Prepare Data\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gc\n",
        "\n",
        "# Load combined DataFrame\n",
        "combined_csv_path = '/content/drive/MyDrive/DEAMds/ProcessedFiles/midi_f_a_f_new.csv'\n",
        "combined_df = pd.read_csv(combined_csv_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "Cg9UAv6lATif",
        "outputId": "3a83dd8d-f10b-4a15-a3fc-e121a34b7fab"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'combined_df' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-ed8a6554d4e3>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Convert columns to numeric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcombined_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombined_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconvert_to_numeric_chunked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mnumeric_dfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'combined_df' is not defined"
          ]
        }
      ],
      "source": [
        "# Convert columns to numeric\n",
        "combined_df.columns = combined_df.columns.str.strip()\n",
        "\n",
        "def convert_to_numeric_chunked(df, chunk_size=100000):\n",
        "    numeric_dfs = []\n",
        "    columns = df.columns\n",
        "    for i in range(0, len(df), chunk_size):\n",
        "        chunk = df.loc[i:i + chunk_size - 1].copy()\n",
        "        for col in columns:\n",
        "            chunk[col] = pd.to_numeric(chunk[col], errors='coerce')\n",
        "        numeric_dfs.append(chunk)\n",
        "        del chunk\n",
        "        gc.collect()\n",
        "    numeric_df = pd.concat(numeric_dfs)\n",
        "    return numeric_df\n",
        "\n",
        "combined_df_numeric = convert_to_numeric_chunked(combined_df)\n",
        "combined_df_numeric.to_csv('/content/drive/MyDrive/DEAMds/ProcessedFiles/final_df_new_try2.csv', index=False)\n",
        "del combined_df\n",
        "gc.collect()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUbtJM9lD467"
      },
      "source": [
        "# Model (RNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmNcQFkSlR1T"
      },
      "source": [
        "## Train test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zUV-4UPrBahg"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gc\n",
        "\n",
        "# Step 6: Train New Model\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load cleaned DataFrame\n",
        "final_csv_path = '/content/drive/MyDrive/DEAMds/ProcessedFiles/final_df_new_try2.csv'\n",
        "final_df = pd.read_csv(final_csv_path)\n",
        "\n",
        "# Extract features and labels\n",
        "X = final_df.drop(columns=['song_id', 'valence_mean', 'valence_std', 'arousal_mean', 'arousal_std']).values\n",
        "\n",
        "# Convert to DataFrame if it's already not a DataFrame\n",
        "X_df = pd.DataFrame(X)\n",
        "\n",
        "# Fill NaN values with 0\n",
        "X_df = X_df.fillna(0)\n",
        "\n",
        "# Convert back to NumPy array if necessary\n",
        "X = X_df.values\n",
        "\n",
        "Y = final_df[['valence_mean', 'valence_std', 'arousal_mean', 'arousal_std']].values\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "features_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(features_scaled, Y, test_size=0.2, random_state=42)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wnl9w2TZQVZm"
      },
      "source": [
        "## MODEL Development"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U67hQdXqs3NP"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Masking, SimpleRNN, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Define the input layer\n",
        "inputs = Input(shape=(X_train.shape[1], 1))\n",
        "\n",
        "# Apply Masking\n",
        "x = Masking(mask_value=0.0)(inputs)\n",
        "\n",
        "# Add RNN layers\n",
        "x = SimpleRNN(64, return_sequences=True, name='simple_rnn_24')(x)\n",
        "x = SimpleRNN(64, name='simple_rnn_25')(x)\n",
        "\n",
        "# Add Dense output layer\n",
        "outputs = Dense(4, name='dense_12')(x)\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs, outputs)\n",
        "\n",
        "# Compile the model (necessary for some operations but not always for building the model)\n",
        "model.compile(optimizer='adam', loss='mse')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b32pYzk1tBn2",
        "outputId": "7d69b8f2-8ab3-4e71-bbde-a30f08e669cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 661ms/step - loss: 5.9284 - val_loss: 0.8450\n",
            "Epoch 2/10\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 635ms/step - loss: 0.7713 - val_loss: 0.8361\n",
            "Epoch 3/10\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 634ms/step - loss: 0.7404 - val_loss: 0.6362\n",
            "Epoch 4/10\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 636ms/step - loss: 0.7090 - val_loss: 0.6379\n",
            "Epoch 5/10\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 637ms/step - loss: 0.6194 - val_loss: 0.6084\n",
            "Epoch 6/10\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 637ms/step - loss: 0.5986 - val_loss: 0.5315\n",
            "Epoch 7/10\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 636ms/step - loss: 0.5595 - val_loss: 0.5226\n",
            "Epoch 8/10\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 635ms/step - loss: 0.5190 - val_loss: 0.4888\n",
            "Epoch 9/10\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 634ms/step - loss: 0.4919 - val_loss: 0.5553\n",
            "Epoch 10/10\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 635ms/step - loss: 0.4835 - val_loss: 0.4463\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 120ms/step - loss: 0.4437\n"
          ]
        }
      ],
      "source": [
        "# Reshape data for RNN (add time dimension)\n",
        "X_train_rnn = np.expand_dims(X_train, axis=-1)\n",
        "X_test_rnn = np.expand_dims(X_test, axis=-1)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train_rnn, y_train, epochs=10, batch_size=1024, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "loss = model.evaluate(X_test_rnn, y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gmtPgS1AWcOo"
      },
      "outputs": [],
      "source": [
        "# Save the trained initial model\n",
        "model.save('/content/drive/MyDrive/grandpa_model.keras')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "1P-5DyIhrM6Q",
        "outputId": "dedc2618-f256-472a-ddd5-a9a8e85b8d3e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2478\u001b[0m, \u001b[38;5;34m1\u001b[0m)        │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ not_equal_1 (\u001b[38;5;33mNotEqual\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2478\u001b[0m, \u001b[38;5;34m1\u001b[0m)        │              \u001b[38;5;34m0\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ masking_1 (\u001b[38;5;33mMasking\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2478\u001b[0m, \u001b[38;5;34m1\u001b[0m)        │              \u001b[38;5;34m0\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ any_1 (\u001b[38;5;33mAny\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2478\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ not_equal_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ simple_rnn_24 (\u001b[38;5;33mSimpleRNN\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2478\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │          \u001b[38;5;34m4,224\u001b[0m │ masking_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                           │                        │                │ any_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ simple_rnn_25 (\u001b[38;5;33mSimpleRNN\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │          \u001b[38;5;34m8,256\u001b[0m │ simple_rnn_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
              "│                           │                        │                │ any_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │            \u001b[38;5;34m260\u001b[0m │ simple_rnn_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2478</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)        │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ not_equal_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2478</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)        │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ masking_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Masking</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2478</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)        │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ any_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Any</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2478</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ not_equal_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ simple_rnn_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2478</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,224</span> │ masking_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                           │                        │                │ any_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ simple_rnn_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ simple_rnn_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
              "│                           │                        │                │ any_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">260</span> │ simple_rnn_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m38,222\u001b[0m (149.31 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">38,222</span> (149.31 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,740\u001b[0m (49.77 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,740</span> (49.77 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m25,482\u001b[0m (99.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,482</span> (99.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBTdB_6NWgg-"
      },
      "source": [
        "## Extract features to transfer knowledge to second model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mY6viiUkrfR9"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Define the feature extractor model\n",
        "layer_name = 'simple_rnn_25'\n",
        "feature_extractor = Model(inputs=model.input, outputs=model.get_layer(layer_name).output)\n",
        "\n",
        "# Now, the feature_extractor model will output the embeddings from the 'simple_rnn_25' layer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjTux6r2r-8V",
        "outputId": "6161b87e-c71c-4fd4-d1f8-aeebaea33e44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3122/3122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m377s\u001b[0m 121ms/step\n",
            "(99894, 64)\n"
          ]
        }
      ],
      "source": [
        "# Assuming X_train_rnn is your training data\n",
        "# Extract features using the feature extractor model\n",
        "X_train_features = feature_extractor.predict(X_train_rnn)\n",
        "\n",
        "# Now X_train_features will have the output from the 'simple_rnn_25' layer\n",
        "print(X_train_features.shape)  # Should print something like (number_of_samples, 64)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Em3OHdoWYdJ"
      },
      "source": [
        "# Model 2 (DNN)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "# Custom activation function to ensure non-negative predictions\n",
        "def custom_activation(x):\n",
        "    return K.maximum(x, 0.37)  # Ensure minimum value is 0.37\n",
        "\n",
        "# Define the model\n",
        "second_model = Sequential([\n",
        "    Input(shape=(22,)),  # Input shape matches the number of MIDI features\n",
        "    Dense(32, activation='relu'),  # First dense layer\n",
        "    Dense(16, activation='relu'),  # Second dense layer\n",
        "    Dense(4, activation=custom_activation)  # Output layer with custom activation\n",
        "])\n",
        "\n"
      ],
      "metadata": {
        "id": "L_A75jSSNzvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transfer weights from the complex model to the simpler model\n",
        "for complex_layer, simpler_layer in zip(model.layers[:-1], second_model.layers[:-1]):\n",
        "    if isinstance(complex_layer, Dense) and isinstance(simpler_layer, Dense):\n",
        "        # Transfer weights\n",
        "        simpler_layer.set_weights(complex_layer.get_weights())\n"
      ],
      "metadata": {
        "id": "qOzXUAazN5zY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Extract features and labels\n",
        "X = final_df[['mean_pitch', 'std_pitch', 'mean_duration', 'std_duration',\n",
        "                 'mean_velocity', 'std_velocity', 'tempo', 'note_density',\n",
        "                 'mean_melodic_interval', 'std_melodic_interval',\n",
        "                 'pitch_class_0', 'pitch_class_1', 'pitch_class_2', 'pitch_class_3',\n",
        "                 'pitch_class_4', 'pitch_class_5', 'pitch_class_6', 'pitch_class_7',\n",
        "                 'pitch_class_8', 'pitch_class_9', 'pitch_class_10', 'pitch_class_11']].values\n",
        "\n",
        "Y = final_df[['valence_mean', 'valence_std', 'arousal_mean', 'arousal_std']].values\n",
        "\n",
        "# Check for consistent lengths\n",
        "print(f\"Features shape: {X.shape}\")\n",
        "print(f\"Labels shape: {Y.shape}\")\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,       # Feature columns\n",
        "    Y,       # Target columns\n",
        "    test_size=0.2,  # 20% of data for testing\n",
        "    random_state=42 # For reproducibility\n",
        ")\n",
        "\n",
        "# Optionally, split the training set into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train,        # Features\n",
        "    y_train,        # Labels\n",
        "    test_size=0.2,  # 20% of training data for validation\n",
        "    random_state=42 # For reproducibility\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQ5QF1HsNvue",
        "outputId": "fa5d05b2-0a23-4b1f-9293-c1a1f43f9b9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features shape: (124868, 22)\n",
            "Labels shape: (124868, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Compile the simpler model\n",
        "second_model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "# Define the early stopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "\n",
        "# Train the simpler model with MIDI features\n",
        "second_model.fit(\n",
        "    X_train,                # Use the training features (midi_features)\n",
        "    y_train,                # Use the training labels\n",
        "    epochs=50,              # Number of epochs\n",
        "    batch_size=1024,        # Batch size\n",
        "    validation_data=(X_val, y_val),  # Validation data (features and labels)\n",
        "     callbacks=[early_stopping]\n",
        ")\n",
        "\n",
        "# Evaluate the simpler model\n",
        "val_loss, val_mae = second_model.evaluate(X_test, y_test)  # Use test set for evaluation\n",
        "print(f\"Test Loss: {val_loss}, Test MAE: {val_mae}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9K9JVIYXPLvg",
        "outputId": "49860a90-34d0-46bf-f915-0e85eb852f5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 183.3622 - mae: 4.2765 - val_loss: 10.8303 - val_mae: 2.7016\n",
            "Epoch 2/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.8371 - mae: 2.6986 - val_loss: 10.8179 - val_mae: 2.6985\n",
            "Epoch 3/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.8668 - mae: 2.7010 - val_loss: 10.8037 - val_mae: 2.6954\n",
            "Epoch 4/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.8459 - mae: 2.6962 - val_loss: 10.7927 - val_mae: 2.6922\n",
            "Epoch 5/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.8018 - mae: 2.6876 - val_loss: 10.7718 - val_mae: 2.6857\n",
            "Epoch 6/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.7972 - mae: 2.6854 - val_loss: 10.7677 - val_mae: 2.6835\n",
            "Epoch 7/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.7601 - mae: 2.6801 - val_loss: 10.7125 - val_mae: 2.6746\n",
            "Epoch 8/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.7151 - mae: 2.6720 - val_loss: 10.7021 - val_mae: 2.6733\n",
            "Epoch 9/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.7170 - mae: 2.6726 - val_loss: 10.6963 - val_mae: 2.6723\n",
            "Epoch 10/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.7057 - mae: 2.6703 - val_loss: 10.6847 - val_mae: 2.6705\n",
            "Epoch 11/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.7119 - mae: 2.6703 - val_loss: 10.6793 - val_mae: 2.6678\n",
            "Epoch 12/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.6996 - mae: 2.6675 - val_loss: 10.6764 - val_mae: 2.6664\n",
            "Epoch 13/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.7167 - mae: 2.6683 - val_loss: 10.6748 - val_mae: 2.6659\n",
            "Epoch 14/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.6516 - mae: 2.6606 - val_loss: 9.6317 - val_mae: 2.5136\n",
            "Epoch 15/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.4258 - mae: 2.2947 - val_loss: 5.7804 - val_mae: 1.8103\n",
            "Epoch 16/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.9463 - mae: 1.6977 - val_loss: 2.9010 - val_mae: 1.3619\n",
            "Epoch 17/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.7651 - mae: 1.3207 - val_loss: 2.4278 - val_mae: 1.2302\n",
            "Epoch 18/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.3796 - mae: 1.2141 - val_loss: 2.1981 - val_mae: 1.1695\n",
            "Epoch 19/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.1983 - mae: 1.1618 - val_loss: 2.0760 - val_mae: 1.1282\n",
            "Epoch 20/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.0861 - mae: 1.1256 - val_loss: 2.0177 - val_mae: 1.1043\n",
            "Epoch 21/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.0522 - mae: 1.1069 - val_loss: 1.9777 - val_mae: 1.0904\n",
            "Epoch 22/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.0103 - mae: 1.0919 - val_loss: 1.9407 - val_mae: 1.0783\n",
            "Epoch 23/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.9720 - mae: 1.0798 - val_loss: 1.9099 - val_mae: 1.0633\n",
            "Epoch 24/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.9476 - mae: 1.0675 - val_loss: 1.8669 - val_mae: 1.0522\n",
            "Epoch 25/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.9086 - mae: 1.0564 - val_loss: 1.8496 - val_mae: 1.0440\n",
            "Epoch 26/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.8705 - mae: 1.0455 - val_loss: 1.8379 - val_mae: 1.0396\n",
            "Epoch 27/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.8699 - mae: 1.0431 - val_loss: 1.8303 - val_mae: 1.0353\n",
            "Epoch 28/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.8730 - mae: 1.0402 - val_loss: 1.8211 - val_mae: 1.0311\n",
            "Epoch 29/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.8550 - mae: 1.0353 - val_loss: 1.8150 - val_mae: 1.0301\n",
            "Epoch 30/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.8445 - mae: 1.0329 - val_loss: 1.8090 - val_mae: 1.0288\n",
            "Epoch 31/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.8374 - mae: 1.0284 - val_loss: 1.8003 - val_mae: 1.0231\n",
            "Epoch 32/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.8287 - mae: 1.0245 - val_loss: 1.7932 - val_mae: 1.0198\n",
            "Epoch 33/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.8272 - mae: 1.0234 - val_loss: 1.7852 - val_mae: 1.0148\n",
            "Epoch 34/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.8287 - mae: 1.0207 - val_loss: 1.7887 - val_mae: 1.0181\n",
            "Epoch 35/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.7998 - mae: 1.0152 - val_loss: 1.7752 - val_mae: 1.0101\n",
            "Epoch 36/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.8034 - mae: 1.0119 - val_loss: 1.7718 - val_mae: 1.0124\n",
            "Epoch 37/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.8068 - mae: 1.0114 - val_loss: 1.7634 - val_mae: 1.0059\n",
            "Epoch 38/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.7974 - mae: 1.0069 - val_loss: 1.7575 - val_mae: 1.0009\n",
            "Epoch 39/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.8005 - mae: 1.0068 - val_loss: 1.7568 - val_mae: 1.0030\n",
            "Epoch 40/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.7808 - mae: 1.0025 - val_loss: 1.7559 - val_mae: 1.0061\n",
            "Epoch 41/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.8039 - mae: 1.0060 - val_loss: 1.7458 - val_mae: 0.9956\n",
            "Epoch 42/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.7726 - mae: 0.9978 - val_loss: 1.7422 - val_mae: 0.9949\n",
            "Epoch 43/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.7697 - mae: 0.9967 - val_loss: 1.7371 - val_mae: 0.9919\n",
            "Epoch 44/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.7661 - mae: 0.9930 - val_loss: 1.7355 - val_mae: 0.9940\n",
            "Epoch 45/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.7514 - mae: 0.9928 - val_loss: 1.7391 - val_mae: 0.9972\n",
            "Epoch 46/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.7786 - mae: 0.9986 - val_loss: 1.7294 - val_mae: 0.9909\n",
            "Epoch 47/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.7614 - mae: 0.9911 - val_loss: 1.7263 - val_mae: 0.9906\n",
            "Epoch 48/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.7609 - mae: 0.9913 - val_loss: 1.7208 - val_mae: 0.9862\n",
            "Epoch 49/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.7474 - mae: 0.9873 - val_loss: 1.6774 - val_mae: 0.9874\n",
            "Epoch 50/50\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.6913 - mae: 0.9804 - val_loss: 1.6503 - val_mae: 0.9700\n",
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1.6947 - mae: 0.9745\n",
            "Test Loss: 1.683762788772583, Test MAE: 0.9719897508621216\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPMjofupLyJ2"
      },
      "source": [
        "# Further testing and analysis of the second model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8a2PoZteVyek"
      },
      "source": [
        "**Checking mean absolute error**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbmMzZ6qJW6b",
        "outputId": "6f5ec166-dcee-447f-d4dc-bfe5a77697c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Mean Absolute Error: 1.0579183609795504\n",
            "Mean Absolute Error for Valence Mean: 0.7257738621257614\n",
            "Mean Absolute Error for Arousal Mean: 1.0361462504863548\n"
          ]
        }
      ],
      "source": [
        "# Predict on the test set\n",
        "y_pred = second_model.predict(X_test)\n",
        "\n",
        "# Calculate Mean Absolute Error (MAE)\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(f\"Mean Absolute Error: {mae}\")\n",
        "\n",
        "# If y_test and y_pred are multi-dimensional (e.g., with multiple outputs), you may need to calculate MAE for each output separately\n",
        "# Assuming y_test and y_pred have shape (n_samples, n_outputs)\n",
        "mae_valence = mean_absolute_error(y_test[:, 0], y_pred[:, 0])\n",
        "mae_arousal = mean_absolute_error(y_test[:, 1], y_pred[:, 1])\n",
        "\n",
        "print(f\"Mean Absolute Error for Valence Mean: {mae_valence}\")\n",
        "print(f\"Mean Absolute Error for Arousal Mean: {mae_arousal}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## checking actual vs predicted min max"
      ],
      "metadata": {
        "id": "FwX5RwLVWcXv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNYBxt6nLw-r",
        "outputId": "75a992bc-1a35-45ed-99a7-c3805f2de79f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 985us/step\n",
            "Predicted Min: 0.3700000047683716, Predicted Max: 8.11032485961914\n"
          ]
        }
      ],
      "source": [
        "# Check min and max of predictions\n",
        "y_pred = second_model.predict(X_test)\n",
        "print(f\"Predicted Min: {np.min(y_pred)}, Predicted Max: {np.max(y_pred)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBn7qnMdLhuB",
        "outputId": "61c53724-54a5-472d-a135-7c612ee5339c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data range: Min = 0.37, Max = 8.1\n",
            "Test data range: Min = 0.37, Max = 8.1\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Extract target values\n",
        "y_train_values = np.array(y_train)\n",
        "y_test_values = np.array(y_test)\n",
        "\n",
        "# Find min and max values for both training and test data\n",
        "train_min = np.min(y_train_values)\n",
        "train_max = np.max(y_train_values)\n",
        "test_min = np.min(y_test_values)\n",
        "test_max = np.max(y_test_values)\n",
        "\n",
        "print(f\"Training data range: Min = {train_min}, Max = {train_max}\")\n",
        "print(f\"Test data range: Min = {test_min}, Max = {test_max}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import save_model\n",
        "\n",
        "# Define the path where you want to save the model\n",
        "model_save_path = '/content/drive/MyDrive/DEAMds/complete_model.keras'\n",
        "\n",
        "# Save the model\n",
        "second_model.save(model_save_path)\n"
      ],
      "metadata": {
        "id": "gdi9qb_pZpJ2"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "BMp24Aklj65g",
        "JTSSZtruLS22",
        "SQcitiw3ojHZ",
        "FhzlazqE0YFA",
        "wZVDVXAn_hCR",
        "PBTdB_6NWgg-",
        "5Em3OHdoWYdJ",
        "YPMjofupLyJ2",
        "FwX5RwLVWcXv"
      ],
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyMNZbHYOqrEyL5FkbeIVeuu",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}